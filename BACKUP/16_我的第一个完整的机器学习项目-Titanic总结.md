# [我的第一个完整的机器学习项目-Titanic总结](https://github.com/geoqiao/gitblog/issues/16)

## 背景
最近一直在学习Python，尝试使用Python解决一些工作上的问题。这里记录参加这次比赛的心得总结，并会给出我的[代码示例(rank：top16%)](https://github.com/geoqiao/Python_DA_100_day/blob/main/kaggle_competition/titanic.py)

Titanic是一个机器学习的入门级分类问题的比赛，数据集记录了titanic乘客的一些信息如性别、票价、船舱等级等信息。数据集被分成train_data 和 test_data两部分。参赛者需要根据train_data的数据信息，利用模型对数据集进行学习，并且预测test_data中乘客是否最终幸存。

titanic数据集的优势是：
1. 数据相对干净，没有特别复杂的数据清理难度
2. 相对简单，可以体验machine learning项目的全流程
3. 比赛不会关闭，可以多次迭代提交
4. 官方有详细的置顶示例项目，基本上如何参加比赛、提交代码、提交预测都有提到，对kaggle新手十分友好
6. 简单，不会劝退机器学习新手

## 比赛过程
整个比赛过程，我总共提交了三次，以下是我的参赛过程。
1. 第一次提交-熟悉比赛流程：  
    在第一次提交之前，我决定使用XGBoost模型来熟悉比赛的整体流程。这有助于我了解数据集的特征、目标变量以及评估指标。熟悉比赛流程对于理解后续的模型选择和优化非常重要。
    
2. 第二次提交-尝试随机森林：  
    在第二次提交时，我决定尝试随机森林模型。然而，结果并不如第一次提交的好。这个经验教会了我，同一模型在不同数据集上的表现可能会有所不同。因此，在机器学习项目中，尝试多个模型是一种明智的策略，这样可以找到最适合数据集的模型。
    
3. 第三次提交-模型清理与比较：  
    根据前两次提交的结果，我意识到模型可能受到了一些问题的影响。因此，我决定对数据进行更多清理工作，包括处理缺失值、处理异常值、one-hot编码、字符转数字等。尝试决策树、随机森林和支持向量机（SVM）等不同模型，并比较它们的评分结果。通过这些比较，我能够更好地理解不同模型的优缺点，并选择最合适的模型进行后续优化。
    
4. 第三次提交-参数优化：  
    在比较了不同模型后，我选择了决策树模型，并使用网格搜索方法进行参数优化。参数优化可以帮助我们找到最佳的参数组合，从而提高模型的性能。通过不断尝试不同的参数组合，我成功地提高了模型的准确性。
    
5. 排名提升：  
    通过应用上述经验，成功地将排名从初始的12000名提升到2300名。这个过程中，我学会了如何有效地处理数据、选择适当的模型以及优化参数。不仅如此，我还学会了如何利用Kaggle平台上的资源和社区，获取更多有关机器学习的知识和技巧。

## 总结收获

1. XGBoost真的很强，大部分数据集可以先用XGBoost跑一遍试试水。
	a. 会自己处理缺失值，我习惯使用seaborn的heatmap看有无缺失值，有些列如果缺失值很少的话会很难看到。
	b.快且效果好，相对与其他模型需要适当调整参数来说，xgboost闭眼跑都能获得不错的效果
2. 对于one-hot处理特征、字符标签转数字等场景，pandas有成熟的方法，想象中很麻烦的操作其实只需要一行代码。
3. 在test_data没有标签的情况下，训练集也可以二次拆分为训练集和测试集，用来在比较模型在不同训练集的表现。
4. 当然，引入KFold 和 cross_val_score也可以解决问题。

# 下一步计划
1. 将学习到的经验应用的工作中的分类问题：预测客户是否会按时还款
2. Python基础：写干净的代码真的很重要，比如这个代码示例，第二次看我已经优点头疼了，函数为什么要那么定义。
3. 写一篇机器学习相关概念的解释blog，例如：kmeans、SVM、随机森林、决策数、XGBoost、